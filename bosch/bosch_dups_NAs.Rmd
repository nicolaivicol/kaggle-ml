---
title: "bosch_dups&NAs"
output: html_document
---

libs
```{r libs}
library(data.table)
library(h2o)
library(zoo)
library(FeatureHashing)
library(Matrix)
library(xgboost)
library(digest)

```
\
udf   
```{r udf}
gc()
sort(round(sapply(ls(),function(x){object.size(get(x))})/sum(sapply(ls(),function(x){object.size(get(x))})), 2), decreasing = T)

udf_quantile <- function(x, p = c(0, 0.005, 0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.98, 0.99, 0.995, 1))
{
  return(quantile(x, probs = p, na.rm = T))
}

```
\
dirs
```{r}
dir_data.raw <- "C:/kaggle/bosch/data.raw/"
dir_data <- "C:/kaggle/bosch/data/"
dir_out.reduced <- "C:/kaggle/bosch/data/reduced/"
isDo <- F
```

\
Eliminate duplicate and all-NA columns
- categorical
```{r}
dir_in <- paste(dir_data.raw, "train_categorical.csv", sep = "")
dir_out <- paste(dir_data, "feat_summary_cat.csv", sep = "")

# reduce duplicate and all-NA columns
# ************************************************************************************
isDo <- F
if (isDo) {
  cols.cat <- fread(paste(dir_data.raw, "train_categorical.csv", sep = ""), nrows = 0, header = T)  
  cols.cat <- colnames(cols.cat)
  
  n_batch  <- 5
  col_idx  <- c(1:length(cols.cat))
  col_bat  <- cut(col_idx, n_batch, labels = c(1:n_batch))
  
  all_features <- vector("list", n_batch)
  all_digests  <- vector("list", n_batch)
  all_isNA  <- vector("list", n_batch)
  
  for(i in seq_along(all_features)) {
    print(i)
    dt <- fread(paste(dir_data.raw, "train_categorical.csv", sep = ""),
                colClasses = "character", na.strings = "", 
                showProgress = F, select = col_idx[col_bat == i])
    all_features[[i]] <- names(dt)
    all_digests[[i]]  <- lapply(dt, digest)
    all_isNA[[i]]  <- lapply(dt, FUN=function(x){mean(is.na(x))})
    rm(dt)
  }
  
  feature_summary <- data.table(feature = unlist(all_features), digest  = unlist(all_digests), 
                                isNA = unlist(all_nonNA))
  feature_summary$duplicate <- duplicated(feature_summary$digest)
  
  write.csv(feature_summary, paste(dir_data, "feat_summary_cat.csv", sep = ""), quote = F, row.names = F)
}

feature_summary <- fread(dir_out, sep = ",")
# 
feature_summary[, list(all = .N, dup = sum(duplicate), isNA = sum(isNA == 1), uniq = sum(!duplicate))]
feature_summary

# unique columns
cols.cat.uniq <- feature_summary[!duplicate & isNA < 1, feature]

# read categorical data again, only non-dup columns
cols.cat <- fread(paste(dir_data.raw, "train_categorical.csv", sep = ""), nrows = 0, header = T)  
cols.class.cat <- c("integer", rep.int("character", ncol(cols.cat)-1)) 

dta_train.cat <- fread(paste(dir_data.raw, "train_categorical.csv", sep = ""), header = T, 
                       colClasses = cols.class.cat, stringsAsFactors=T,
                       select = cols.cat.uniq, sep = ",")
# append Response to date data
dta_train.num <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""), 
                       sep = ",", header = T,
                       select = c("Id", "Response"))
dta_train.cat$Response <- dta_train.num$Response

dim(dta_train.cat)
colnames(dta_train.cat)

# reduced:
1-(length(cols.cat.uniq) - 2)/(nrow(feature_summary) - 1)
# 0.895

# write out categorical data to reduced file
write.csv(dta_train.cat, paste(dir_out.reduced, "train_categorical.csv", sep = ""), quote = F, row.names = F)


# reduce categorical columns that have <=2 observations != "" and response = 0
# ***********************************************************************************************
feature_summary$tagCount <- NA
feature_summary$resp1Count <- NA

mx_cols <- setdiff(colnames(dta_train.cat), c("Id", "Response"))

for (mx_i in 1:nrow(feature_summary)) {
  # mx_i <- 225
  mx_col <- feature_summary$feature[mx_i]
  print(mx_col)
  print((mx_col %in% mx_cols))
  # mx_col <- "L0_S1_F27"
  if (mx_col %in% mx_cols) {
    feature_summary$tagCount[mx_i] <- sum(dta_train.cat[, mx_col, with = F] != "")
    feature_summary$resp1Count[mx_i]<- sum(dta_train.cat[, mx_col, with = F] != "" & dta_train.cat[, Response == 1])
  }
}
write.csv(feature_summary, paste(dir_data, "feat_summary_cat.csv", sep = ""), quote = F, row.names = F)

feature_summary[resp1Count > 0, ]
feature_summary[tagCount <= 2, ]

# unique columns
cols.cat.uniq <- feature_summary[(!duplicate & isNA < 1) & !(tagCount <= 2 & resp1Count == 0), feature]
cols.cat.uniq <- unique(c("Id", cols.cat.uniq, "Response"))

dta_train.cat <- dta_train.cat[, cols.cat.uniq, with = F]

# reduced:
1-(ncol(dta_train.cat) - 2)/(nrow(feature_summary) - 1)
# 0.9056075
ncol(dta_train.cat) - 2; nrow(feature_summary) - 1
# keep only 202 from 2140

write.csv(dta_train.cat, paste(dir_out.reduced, "train_categorical.csv", sep = ""), quote = F, row.names = F)


```
\
- numeric
```{r}
isDo <- F
if (isDo) {
  cols.num <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""), nrows = 0, header = T)  
  cols.num <- colnames(cols.num)

  n_batch  <- 5
  col_idx  <- c(1:length(cols.num))
  col_bat  <- cut(col_idx, n_batch, labels = c(1:n_batch))

  all_features <- vector("list", n_batch)
  all_digests  <- vector("list", n_batch)
  all_isNA  <- vector("list", n_batch)

  for(i in seq_along(all_features)) {
  print(i)
  dt <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""),
              #colClasses = "integer", na.strings = "", 
              showProgress = F, select = col_idx[col_bat == i])
  all_features[[i]] <- names(dt)
  all_digests[[i]]  <- lapply(dt, digest)
  all_isNA[[i]]  <- lapply(dt, FUN=function(x){mean(is.na(x))})
  rm(dt)
  }

  feature_summary <- data.table(feature = unlist(all_features), 
                              digest  = unlist(all_digests), 
                              isNA = unlist(all_isNA))
  feature_summary$duplicate <- duplicated(feature_summary$digest)

  write.csv(feature_summary, paste(dir_data, "feat_summary_num.csv", sep = ""), quote = F, row.names = F)
}

feature_summary <- fread(paste(dir_data, "feat_summary_num.csv", sep = ""), sep = ",")
feature_summary[, list(all = .N, dup = sum(duplicate), isNA = sum(isNA == 1), uniq = sum(!duplicate))]
feature_summary[duplicate == T | isNA == 1, ]

cols.num.uniq <- feature_summary[!duplicate & isNA < 1, feature]
# reduced by:
1 - length(cols.num.uniq)/nrow(feature_summary)

# read numeric
cols.num <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""), nrows = 0, header = T)  
colnames(cols.num)

dta_train.num <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""), 
                       sep = ",", header = T, 
                       #colClasses = cols.class.num, 
                       select = cols.num.uniq)


# reduce numerical columns that have <=2 non-NA observations and response = 0
# ***********************************************************************************************
feature_summary$tagCount <- NA
feature_summary$resp1Count <- NA

mx_cols <- colnames(dta_train.num)

for (mx_i in 1:nrow(feature_summary)) {
  # mx_i <- 225
  mx_col <- feature_summary$feature[mx_i]
  print(mx_col)
  print((mx_col %in% mx_cols))
  if (mx_col %in% mx_cols) {
    feature_summary$tagCount[mx_i] <- sum(!is.na(dta_train.num[, mx_col, with = F]))
    feature_summary$resp1Count[mx_i]<- sum(!is.na(dta_train.num[, mx_col, with = F]) & dta_train.num[, Response == 1])
  }
}
dim(dta_train.num)

feature_summary[resp1Count > 0, ]
feature_summary[isNA > 0.99, ]



# reduce highly correlated columns
# ***********************************************************************************************
dta_train.num[!is.na(L1_S24_F907), .(L1_S24_F907, L1_S24_F920)]

cor.table <- cor(dta_train.num[, 1:10, with = F], use = "complete")

gc()

```
\
- date
- eliminate duplicates for station
- keep only one or several non-redundant date columns for station
```{r}
isDo <- F
dir_in <- paste(dir_data.raw, "train_date.csv", sep = "")
dir_out <- paste(dir_data, "feat_summary_date.csv", sep = "")

# reduce duplicate and all-NA columns
# ************************************************************************************
if (isDo) {
  cols.num <- fread(dir_in, nrows = 0, header = T)  
  cols.num <- colnames(cols.num)

  n_batch  <- 5
  col_idx  <- c(1:length(cols.num))
  col_bat  <- cut(col_idx, n_batch, labels = c(1:n_batch))

  all_features <- vector("list", n_batch)
  all_digests  <- vector("list", n_batch)
  all_isNA  <- vector("list", n_batch)

  for(i in seq_along(all_features)) {
  print(i)
  dt <- fread(dir_in,
              #colClasses = "integer", na.strings = "", 
              showProgress = F, select = col_idx[col_bat == i])
  all_features[[i]] <- names(dt)
  all_digests[[i]]  <- lapply(dt, digest)
  all_isNA[[i]]  <- lapply(dt, FUN=function(x){mean(is.na(x))})
  rm(dt)
  }

  feature_summary <- data.table(feature = unlist(all_features), 
                              digest  = unlist(all_digests), 
                              isNA = unlist(all_isNA))
  feature_summary$duplicate <- duplicated(feature_summary$digest)

  write.csv(feature_summary, dir_out, quote = F, row.names = F)
}

feature_summary <- fread(dir_out, sep = ",")
cols.date.uniq <- feature_summary[!duplicate & isNA < 1, feature]

nrow(feature_summary)
sum(feature_summary$duplicate); sum(feature_summary$duplicate)/nrow(feature_summary)
sum(!feature_summary$duplicate)
sum(feature_summary$isNA == 1)

head(feature_summary[duplicate == T, ], 25)
head(feature_summary[, ], 25)

# how many stations
cols.date.mod <- feature_summary$feature[grep("_S", feature_summary$feature)]
mx_x1 <- regexpr("_S", cols.date.mod)[1:length(cols.date.mod)]
mx_x2 <- regexpr("_D", cols.date.mod)[1:length(cols.date.mod)]
mx_stations <- unique(substr(cols.date.mod, mx_x1, mx_x2))
mx_stations
length(mx_stations)

# read date data again, only non-dup columns
dta_train.date <- fread(dir_in, 
                        sep = ",", header = T, 
                        select = cols.date.uniq) #cols.date.uniq
# append Response to date data
dta_train.num <- fread(paste(dir_data.raw, "train_numeric.csv", sep = ""), 
                       sep = ",", header = T,
                       select = c("Id", "Response"))
dim(dta_train.date)
colnames(dta_train.date)
dta_train.date$Response <- dta_train.num$Response

# reduce columns identical when having values, over write next column to first column of station
# **************************************************************************************************
# still some duplicate columns left, identical where rows have values, different on NAs
# example
dta_train.date[, mx := L0_S1_D26 - L0_S1_D30]
dta_train.date[, list(isNA = sum(is.na(mx))/.N, 
                      isZero = sum(mx == 0, na.rm = T)/.N, 
                      isDif = sum(mx != 0, na.rm = T)/.N, 
                      col1_NAs = sum(is.na(L0_S1_D26))/.N,
                      col2_NAs = sum(is.na(L0_S1_D30))/.N)]
summary(dta_train.date$mx)

# run digest again
all_digests <- lapply(dta_train.date, digest)
all_digests <- unlist(all_digests)
feature_summary2 <- data.table(feature = names(all_digests), 
                              digest  = all_digests)
feature_summary2$duplicate <- duplicated(feature_summary2$digest)
summary(feature_summary2)
# digest can't identify any duplicates

# run a one-by-one comparison for each station
mx_i_dups <- c()
for (mx_i_s in 1:length(mx_stations)) {
  #mx_i_s <- 10
  #mx_stations[mx_i_s]
  mx_cols <- cols.date.uniq[grep(mx_stations[mx_i_s], cols.date.uniq)]
  #mx_cols
  if (length(mx_cols) == 0) {
    print("stop! - no date for station?")
    break
    } else if (length(mx_cols) > 1) {
      for (i1 in 1:(length(mx_cols)-1))
      {
        if (mx_cols[i1] %in% mx_i_dups) {next }
        for (i2 in (i1+1):length(mx_cols))
        {
          if (mx_cols[i2] %in% mx_i_dups) {next }
          print(paste(mx_cols[i1], mx_cols[i2]))
          mx_sumdif <- sum(dta_train.date[, mx_cols[i1], with = F] - dta_train.date[, mx_cols[i2], with = F], na.rm = T)
          if (mx_sumdif == 0) {
            mx_i_dups <- c(mx_i_dups, mx_cols[i2])
            print(paste("dup:", mx_cols[i2]))
            dta_train.date$mx1 <- dta_train.date[, mx_cols[i1], with = F]
            dta_train.date$mx2 <- dta_train.date[, mx_cols[i2], with = F]
            print(paste("overwritten NAs:", dta_train.date[, sum(!is.na(mx2) & is.na(mx1))]))
            dta_train.date[!is.na(mx2) & is.na(mx1), mx1 := mx2]
            dta_train.date[, mx_cols[i1]] <- dta_train.date[, mx1]
          }
        }
      }
    }
}
mx_i_dups

cols.date.uniq <- setdiff(cols.date.uniq, mx_i_dups)
cols.date.uniq

# check: all stations present? (52 stations)
cols.date.mod2 <- cols.date.uniq[grep("_S", cols.date.uniq)]
mx_x1 <- regexpr("_S", cols.date.mod2)[1:length(cols.date.mod2)]
mx_x2 <- regexpr("_D", cols.date.mod2)[1:length(cols.date.mod2)]
mx_stations <- unique(substr(cols.date.mod2, mx_x1, mx_x2))
mx_stations
length(mx_stations)
# yes. all good.

# keep only unique columns
dta_train.date <- dta_train.date[, c(cols.date.uniq, "Response"), with = F]
summary(dta_train.date)
colnames(dta_train.date)


# manual check, reduce alike columns (same but shifted by a constant time units)
# station 24, 25
# ************************************************************************************
mx_L1_S24_D677 <- c("L1_S24_D697", "L1_S24_D801", "L1_S24_D804", "L1_S24_D807", "L1_S24_D813", "L1_S24_D818", "L1_S24_D909", "L1_S24_D999", "L1_S24_D1062")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S24_D677)

mx_L1_S24_D1116 <- c("L1_S24_D1135", "L1_S24_D1163", "L1_S24_D1168", "L1_S24_D1171", "L1_S24_D1178", "L1_S24_D1186", "L1_S24_D1277", "L1_S24_D1368", "L1_S24_D1413", "L1_S24_D1457")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S24_D1116)
cols.date.uniq 

mx_L1_S24_D1511 <- c("L1_S24_D1522", "L1_S24_D1566", "L1_S24_D1568", "L1_S24_D1570", "L1_S24_D1576", "L1_S24_D1583", "L1_S24_D1674", "L1_S24_D1765", "L1_S24_D1809", "L1_S24_D1826")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S24_D1511)
cols.date.uniq

mx_L1_S25_D1854 <- c("L1_S25_D1867", "L1_S25_D1883", "L1_S25_D1887", "L1_S25_D1891", "L1_S25_D1898", "L1_S25_D1902", "L1_S25_D1980", "L1_S25_D2058", "L1_S25_D2098", "L1_S25_D2138")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S25_D1854)
cols.date.uniq

mx_L1_S25_D2230 <- c("L1_S25_D2238", "L1_S25_D2240", "L1_S25_D2248", "L1_S25_D2251", "L1_S25_D2329", "L1_S25_D2406", "L1_S25_D2445")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S25_D2230)
cols.date.uniq

mx_L1_S25_D2497 <- c("L1_S25_D2505", "L1_S25_D2507", "L1_S25_D2515", "L1_S25_D2518", "L1_S25_D2674", "L1_S25_D2713", "L1_S25_D2728")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S25_D2497)
cols.date.uniq

mx_L1_S25_D2780 <- c("L1_S25_D2788", "L1_S25_D2790", "L1_S25_D2798", "L1_S25_D2801", "L1_S25_D2879", "L1_S25_D2957", "L1_S25_D2996", "L1_S25_D3011")
cols.date.uniq <- setdiff(cols.date.uniq, mx_L1_S25_D2780)
cols.date.uniq

# code to manually select date features to reduce
dta_train.date[, d1 := L1_S25_D2780]
dta_train.date[, d2 := L1_S25_D3011]
dta_train.date[, list(isDif = sum(d1 != d2, na.rm = T)/.N,
                      isEqual = sum(d1 == d2, na.rm = T)/.N,
                      isNA1 = sum(is.na(d1))/.N,
                      isNA2 = sum(is.na(d2))/.N,
                      isNA1_notNA2 = sum(is.na(d1) & !is.na(d2))/.N,
                      notNA1_isNA2 = sum(!is.na(d1) & is.na(d2))/.N)]
dta_train.date[d1 != d2, list(count = length(Id), meanResp = mean(Response))]
dta_train.date[(d1 - d2) < -0.10, list(count = length(Id), meanResp = mean(Response))]
udf_quantile(dta_train.date[d1 != d2, d1 - d2])

# keep only non-redundant columns
dta_train.date <- dta_train.date[, c(cols.date.uniq, "Response"), with = F]
summary(dta_train.date)
colnames(dta_train.date)

# reduced:
1-(length(cols.date.uniq) - 1)/(nrow(feature_summary) - 1)
# ~ 0.95

# write out reduced date data
write.csv(dta_train.date, paste(dir_out.reduced, "train_date.csv", sep = ""), quote = F, row.names = F)

gc()

```

